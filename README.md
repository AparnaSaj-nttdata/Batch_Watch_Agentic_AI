# BatchWatch AI - Intelligent Batch Job Monitoring System

An AI-powered monitoring and prediction system for Autosys batch jobs using a custom LLM API. It provides real-time analytics, long-running job detection, failure trends, future runtime prediction, SLA risk alerts, and an AI assistant for natural-language insights.

---

## ğŸŒŸ Features

- **Real-time Monitoring**: Track job execution status, runtime, and failures across multiple applications.
- **Long Running Job Detection**: Automatically identify jobs running significantly longer than historical averages.
- **Failure Pattern Analysis**: Aggregate and analyze failures on a daily, weekly, and monthly basis.
- **Predictive Analytics**: Forecast future job runtimes and identify potential SLA breach risks.
- **AI-Powered Insights**: Use natural language to ask questions about job performance and get context-aware answers.
- **Role-Based Dashboards**: Separate views for Batch Operations Teams (cross-application) and Application Owners (single-application).
- **Executive Summaries**: Auto-generate dashboard summaries for leadership with a single click.

---

## ğŸ“‹ Requirements

- Python 3.9+
- Access to your custom NTT AI API with valid credentials.
- A network environment that can successfully reach your API endpoint.

---

## ğŸ“¦ Project Structure

```
batch-watch-ai/
â”œâ”€â”€ app.py                      # Main Streamlit application (UI and dashboard)
â”œâ”€â”€ analytics.py                # Analytics engine (long runners, failures, predictions, alerts)
â”œâ”€â”€ ai_agent.py                 # AI agent (RAG via TF-IDF + your custom LLM)
â”œâ”€â”€ data_generator.py           # Synthetic data generator for creating a sample dataset
â”œâ”€â”€ requirements.txt            # Project dependencies
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ LLM.py                  # Your MyCustomLLM wrapper class
â”‚   â”œâ”€â”€ auth.py                 # Your authenticate() implementation
â”‚   â””â”€â”€ llm_service.py          # Your llm_chat(prompt, max_tokens) function
â”œâ”€â”€ ntt_secrets.py              # NTT_ID and any other secrets (do not commit to git)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ autosys_jobs.csv        # Generated data file
â””â”€â”€ vector_store.pkl            # Cached knowledge base for RAG (auto-generated)
```

---

## ğŸš€ Installation

1.  **Create and activate a virtual environment:**

    ```bash
    # For Windows
    python -m venv venv
    venv\Scripts\activate

    # For macOS/Linux
    python3 -m venv venv
    source venv/bin/activate
    ```

2.  **Install the required dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

---

## ğŸ” Configuration

1.  **Create `ntt_secrets.py` in the project root directory:**

    ```python
    # ntt_secrets.py
    NTT_ID = "your-actual-ntt-id-here"
    NTT_SECRET = "your-actual-secret-key"
    ```


2.  **Verify your `services/llm_service.py` is correct (as you provided):**

    ```python
    from services.LLM import MyCustomLLM
    from services.auth import authenticate
    from ntt_secrets import NTT_ID

    def llm_chat(prompt, max_tokens=4000):
        token = authenticate()
        llm = MyCustomLLM(
            api_url='https://api.ntth.ai/v1/chat',
            token=token,
            # model_id="cc5bab32-9ccf-472b-9d76-91fc2ec5b047", # GPT-4o-mini
            model_id="6c26a584-a988-4fed-92ea-f6501429fab9", # GPT-4o
            # model_id="a4022a51-2f02-4ba7-8a31-d33c7456b58e", # Gemini 2.5 Flash
            ID=NTT_ID,
            max_tokens=max_tokens
        )
        return llm._call(prompt)
    ```

4.  Ensure your `services/LLM.py` file contains your working `MyCustomLLM` class that correctly calls the API.

---

## ğŸ§ª Generate Sample Data

Run the data generator script from your terminal. This will create the `data/autosys_jobs.csv` file.

```bash
python data_generator.py
```

---

## â–¶ï¸ Run the Application

Launch the Streamlit app from your terminal.

```bash
streamlit run app.py
```

The application will open in your default web browser, typically at `http://localhost:8501`.

---

## ğŸ§­ Using the App

-   **Role Selection (Sidebar)**:
    -   `Batch Operations Team`: Select multiple applications for a cross-application monitoring view.
    -   `Application Owner`: Select a single application for a deep-dive, focused view.
-   **Max Response Tokens (Sidebar)**: Adjust the slider to control the maximum length of answers from the AI Assistant.

### Tabs Overview

-   **ğŸ“Š Overview**: High-level application KPIs, runtime trends, and job distribution charts.
-   **âš ï¸ Long Running Jobs**: Detects jobs running >1.5x their historical average (threshold is adjustable). Provides root cause indicators and an AI analysis button.
-   **âŒ Failure Analysis**: Aggregates failures by day/week/month, shows job-level failure rates, and offers AI-powered pattern analysis.
-   **ğŸ”® Predictions**: Forecasts future job runtimes with confidence intervals and risk levels. Estimates application completion times.
-   **ğŸš¨ Alerts & SLA**: Displays active alerts by severity and tracks SLA compliance rates over time.
-   **ğŸ¤– AI Assistant**: Ask questions in natural language. Features executive summary generation, quick questions, and shows the context used for answers.

**Tip**: If data seems stale, use the **Refresh Data** button in the app's footer to clear caches and reload everything.

---

## ğŸ› ï¸ Troubleshooting

-   **Error: API request failed - 400 Bad Request**:
    -   Verify your `authenticate()` function returns the correct token format (e.g., does it need a `Bearer ` prefix?).
    -   Confirm the `modelId` and other payload fields in `services/LLM.py` match your API's specification exactly.

-   **Error querying LLM: 'token' or other auth issues**:
    -   This often happens due to caching. Click the **Refresh Data** button in the app to clear the cache.
    -   Run the authentication test script below to ensure your `auth.py` and `ntt_secrets.py` are correct.

-   **SSL errors with model downloads**:
    -   This should not occur. The app now uses TF-IDF for embeddings, which requires no external model downloads from HuggingFace.

-   **Cache-related or stale data**:
    -   Use the **Refresh Data** button in the app.
    -   As a last resort, manually delete the `vector_store.pkl` file to force a full knowledge base rebuild on the next app run.

---

## ğŸ§ª Quick Tests

-   **Validate Authentication**:

    ```bash
    python -c "from services.auth import authenticate; print(f'Token received: {authenticate()[:50]}...')"
    ```

-   **Validate LLM Connection**:

    ```bash
    python -c "from services.llm_service import llm_chat; print(llm_chat('Say hello in one sentence', 100))"
    ```

-   **Validate Analytics Engine (in a Python shell)**:

    ```python
    from analytics import BatchAnalytics
    import pandas as pd
    df = pd.read_csv('data/autosys_jobs.csv', parse_dates=['run_date','start_time','end_time'])
    analytics = BatchAnalytics(df)
    print('Long runners found:', len(analytics.identify_long_running_jobs()))
    print('Failures by job:', len(analytics.analyze_failures()['by_job']))
    print('Sample prediction:', analytics.predict_future_runtime(df['job_id'].iloc[0], days_ahead=14))
    ```

---

## ğŸ”’ Security

-   **Never commit secrets to version control.** Add the following files to your `.gitignore`:
    -   `ntt_secrets.py`
    -   `services/auth.py`
    -   `vector_store.pkl`
-   Tokens are retrieved on each call, not stored long-term in the application state.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Streamlit UI (app.py)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Overview â”‚  Long    â”‚ Failures â”‚Predictionsâ”‚   AI     â”‚  â”‚
â”‚  â”‚          â”‚ Runners  â”‚          â”‚           â”‚Assistant â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BatchAnalytics     â”‚        â”‚ BatchWatchAgent â”‚
â”‚  (analytics.py)     â”‚        â”‚  (ai_agent.py)  â”‚
â”‚ - long runners      â”‚        â”‚ - TF-IDF RAG    â”‚
â”‚ - failures          â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”¤ - prompt build  â”‚
â”‚ - predictions       â”‚        â”‚ - llm_chat call â”‚
â”‚ - alerts            â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚  llm_chat()    â”‚
                                â”‚ (llm_service)  â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚  MyCustomLLM   â”‚
                                â”‚   (LLM.py)     â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚ authenticate() â”‚
                                â”‚   (auth.py)    â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚  NTT AI API    â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”® Future Enhancements

-   Real-time streaming updates and notifications (e.g., to Slack/Teams).
-   Deeper anomaly detection using machine learning models.
-   Dependency-aware critical path analysis for more accurate SLA predictions.
-   Cost and resource optimization insights based on job performance.
-   User authentication and role-based access control within the app.

---

## âœ… Quick Start Summary

1.  Configure `ntt_secrets.py` and `services/auth.py`.
2.  Install dependencies: `pip install -r requirements.txt`
3.  Generate sample data: `python data_generator.py`
4.  Launch the app: `streamlit run app.py`

Enjoy using BatchWatch AI!
